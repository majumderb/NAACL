{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Chunk starts with pure number. No decimal.\n",
    "2\t((\tNP\t<fs name='NP2' drel='rh:VGF'>\n",
    "Here NP is parts of speech, NP2 is node-name, and drel contains dependency relation. rh is relation-type, VGF is relation-with.\n",
    "\n",
    "Chunk has token which starts with chunk number.(0-9)\n",
    "example-  2.1\txarSana\tN_NN\t<fs af='xarSana,n,m,sg,3,o,0,0' name='xarSana'>\n",
    "\n",
    "N-NN is parts of speech.\n",
    "\n",
    "We need to look for af mentioned here. Look there are 7 commas. That means we expect there should be 8 fields inside af. <fs af='xarSana,n,m,sg,3,o,0,0'....>\n",
    "\n",
    "These 8 fields are root, gender, number, person, tense, aspect, modality\n",
    "\n",
    "\n",
    "Note: Sometimes chunk can also have 'af' - we may need to store that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re;\n",
    "\n",
    "'''This function to read a sentence block, returns list of sentences'''\n",
    "def readSentence(ssfFileId):\n",
    "    lst=[];\n",
    "    for line in ssfFileId:\n",
    "        m=re.match(\"</Sentence>\\n\",line);\n",
    "        if m:\n",
    "            break;\n",
    "        else: \n",
    "            lst.extend([line]);\n",
    "    return lst;\n",
    "\n",
    "'''This function is to read each chunk inside a sentence, chunks are mainly phrases'''\n",
    "def getChunkIndex(lst):\n",
    "    index=0;\n",
    "    indexLst=[];\n",
    "    for i in lst:\n",
    "        m=re.search('[0-9]+\\t\\(\\(',i);\n",
    "        index=index+1;\n",
    "        if m:\n",
    "            indexLst.extend([index]);\n",
    "\n",
    "    print(indexLst);\n",
    "\n",
    "    return indexLst;\n",
    "\n",
    "'''This function is to read inside a sentence and extract tags'''\n",
    "def getConnlofChunk(index,lst):\n",
    "    try:\n",
    "        pat= \"[1-9]+\\s*\\(\\(\\s*([A-Z]+)\\s*<fs\\s*name=\\'([A-Z1-9]+)\\'\\s*drel=\\'([a-z0-9]+):([A-Z0-9]+)\\'>\\n\";\n",
    "#         print(lst[index-1]);\n",
    "        m=re.match(pat,lst[index-1]);\n",
    "        print(m)\n",
    "        if m:\n",
    "            sentence = {}\n",
    "            print(m.group(0))\n",
    "            print(m.group(1));\n",
    "            chunkType=m.group(1);\n",
    "            print(m.group(2));\n",
    "            chunkIs=m.group(2);\n",
    "            print(m.group(3));\n",
    "            relType=m.group(3);\n",
    "            attachEd=m.group(4);\n",
    "            print(attachEd)\n",
    "            print(m.group(5))\n",
    "    except Exception:\n",
    "        None\n",
    "\n",
    "    try:\n",
    "        pat= \"[1-9]+\\s*\\(\\(\\s*([A-Z]+)\\s*<fs\\s+af=\\'([A-Za-z0-9,]+)\\'\\s+name=\\'([A-Z1-9]+)\\'\\s*drel=\\'([a-z0-9]+):([A-Z0-9]+)\\'>\\n\";\n",
    "#         print(lst[index-1]);\n",
    "        m=re.match(pat,lst[index-1]);\n",
    "        print(m)\n",
    "        if m:\n",
    "            print(m.group(1));\n",
    "            chunkType=m.group(1);\n",
    "            print(m.group(2));\n",
    "            chunkIs=m.group(2);\n",
    "            print(m.group(3));\n",
    "            relType=m.group(3);\n",
    "            attachEd=m.group(4);\n",
    "            print(attachEd)\n",
    "            print(m.group(5))\n",
    "    \n",
    "    except Exception:\n",
    "        None \n",
    "        \n",
    "    '''This loop is for reading the tokens inside the chunk, please store them separately with some identifier'''\n",
    "    pat2=\"[0-9]+\\.[0-9]+\\s+([a-zA-Z]+)\\s+([A-Z_]+)\\s+<fs\\s+af=\\'([A-Za-z0-9,]+)\\'\\s+name=\\'([A-Za-z]+)\\'>\"\n",
    "    while True:\n",
    "            index=index+1;\n",
    "            m=re.match(pat,lst[index-1]);\n",
    "            if m:\n",
    "                print(m.group(1));\n",
    "                tocken=m.group(1);\n",
    "                print(m.group(2));\n",
    "                PoS=m.group(2);\n",
    "                print(m.group(3));\n",
    "                PoS=m.group(3);\n",
    "\n",
    "            else:\n",
    "                break;\n",
    "\n",
    "    return;\n",
    "\n",
    "        \n",
    "    return; #@rajesh, here you need to return the dictionary for each sentences\n",
    "\n",
    "\n",
    "def getConllofSentence(lst):\n",
    "    conllList=[];\n",
    "    chunkIndexLst=getChunkIndex(lst);\n",
    "\n",
    "    for element in chunkIndexLst:\n",
    "        getConnlofChunk(element,lst);\n",
    "        #conllList.extend(listofTockensConll);\n",
    "\n",
    "#     print(conllList)\n",
    "\n",
    "    return;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"<Sentence id='1'>\\n\", \"1\\t((\\tNP\\t<fs af=',,,,,,,' name='NP' drel='nmod:NP2'>\\n\", \"1.1\\tsakAla\\tN__NN\\t<fs af=',,,,,,,' name='sakAla'>\\n\", '))\\n', \"2\\t((\\tNP\\t<fs name='NP2' drel='k7t:VGF'>\\n\", \"2.1\\tsAdZeV\\tQT__QTF\\t<fs af=',,,,,,,' name='sAdZeV'>\\n\", \"2.2\\tAtatAyZa\\tN__NN\\t<fs name='AtatAyZa'>\\n\", '))\\n', \"3\\t((\\tNP\\t<fs af=',,,,,,,' name='NP3' drel='k5:VGF'>\\n\", \"3.1\\twiswA-woVrsA\\tN__NNP\\t<fs name='wiswA-woVrsA'>\\n\", \"3.2\\teVksapreVsa\\tN__NN\\t<fs name='eVksapreVsa'>\\n\", \"3.3\\tWeVkeV\\tPSP\\t<fs name='WeVkeV'>\\n\", '))\\n', \"4\\t((\\tNP\\t<fs af=',,,,,,,' name='NP4' drel='k7p:VGF'>\\n\", \"4.1\\tniu\\tJJ\\t<fs name='niu'>\\n\", \"4.2\\tAlipuraxuyZAra\\tN__NNP\\t<fs name='AlipuraxuyZAra'>\\n\", \"4.3\\tsteVSaneV\\tN__NN\\t<fs name='steVSaneV'>\\n\", '))\\n', \"5\\t((\\tVGF\\t<fs af=',,,,,,,' stype='declarative' voicetype='active' name='VGF'>\\n\", \"5.1\\tneVmeV\\tV__VM\\t<fs af=',,,,,,,' name='neVmeV'>\\n\", \"5.2\\tpadZalAma\\tV__VAUX\\t<fs name='padZalAma'>\\n\", '))\\n', \"6\\t((\\tBLK\\t<fs af=',,,,,,,' name='BLK' drel='rsym:VGF'>\\n\", \"6.1\\t.\\tRD__PUNC\\t<fs name='.'>\\n\", '))\\n']\n",
      "3\t((\tNP\t<fs af=',,,,,,,' name='NP3' drel='k5:VGF'>\n",
      "\n",
      "[2, 5, 9, 14, 19, 23]\n",
      "None\n",
      "<_sre.SRE_Match object; span=(0, 52), match=\"1\\t((\\tNP\\t<fs af=',,,,,,,' name='NP' drel='nmod:>\n",
      "NP\n",
      ",,,,,,,\n",
      "NP\n",
      "nmod\n",
      "NP2\n",
      "<_sre.SRE_Match object; span=(0, 39), match=\"2\\t((\\tNP\\t<fs name='NP2' drel='k7t:VGF'>\\n\">\n",
      "2\t((\tNP\t<fs name='NP2' drel='k7t:VGF'>\n",
      "\n",
      "NP\n",
      "NP2\n",
      "k7t\n",
      "VGF\n",
      "None\n",
      "None\n",
      "<_sre.SRE_Match object; span=(0, 51), match=\"3\\t((\\tNP\\t<fs af=',,,,,,,' name='NP3' drel='k5:V>\n",
      "NP\n",
      ",,,,,,,\n",
      "NP3\n",
      "k5\n",
      "VGF\n",
      "None\n",
      "<_sre.SRE_Match object; span=(0, 52), match=\"4\\t((\\tNP\\t<fs af=',,,,,,,' name='NP4' drel='k7p:>\n",
      "NP\n",
      ",,,,,,,\n",
      "NP4\n",
      "k7p\n",
      "VGF\n",
      "None\n",
      "None\n",
      "None\n",
      "<_sre.SRE_Match object; span=(0, 54), match=\"6\\t((\\tBLK\\t<fs af=',,,,,,,' name='BLK' drel='rsy>\n",
      "BLK\n",
      ",,,,,,,\n",
      "BLK\n",
      "rsym\n",
      "VGF\n"
     ]
    }
   ],
   "source": [
    "'''Main'''\n",
    "\n",
    "fileId=open('bengali_sample.txt','r');\n",
    "lst=readSentence(fileId);\n",
    "\n",
    "getConllofSentence(lst);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
