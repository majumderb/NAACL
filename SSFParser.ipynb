{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Chunk starts with pure number. No decimal.\n",
    "2\t((\tNP\t<fs name='NP2' drel='rh:VGF'>\n",
    "Here NP is parts of speech, NP2 is node-name, and drel contains dependency relation. rh is relation-type, VGF is relation-with.\n",
    "\n",
    "Chunk has token which starts with chunk number.(0-9)\n",
    "example-  2.1\txarSana\tN_NN\t<fs af='xarSana,n,m,sg,3,o,0,0' name='xarSana'>\n",
    "\n",
    "N-NN is parts of speech.\n",
    "\n",
    "We need to look for af mentioned here. Look there are 7 commas. That means we expect there should be 8 fields inside af. <fs af='xarSana,n,m,sg,3,o,0,0'....>\n",
    "\n",
    "These 8 fields are root, gender, number, person, tense, aspect, modality\n",
    "\n",
    "\n",
    "Note: Sometimes chunk can also have 'af' - we may need to store that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re;\n",
    "\n",
    "'''This function to read a sentence block, returns list of sentences'''\n",
    "def readSentence(ssfFileId):\n",
    "    lst=[]\n",
    "    for line in ssfFileId:\n",
    "        m=re.match(\"</Sentence>\\n\",line)\n",
    "        if m:\n",
    "            break\n",
    "        else: \n",
    "            lst.extend([line])\n",
    "    return lst\n",
    "\n",
    "'''This function is to read each chunk inside a sentence, chunks are mainly phrases'''\n",
    "def getChunkIndex(lst):\n",
    "    index=0;\n",
    "    indexLst=[]\n",
    "    for i in lst:\n",
    "        m=re.search('[0-9]+\\t\\(\\(',i)\n",
    "        index=index+1\n",
    "        if m:\n",
    "            indexLst.extend([index])\n",
    "\n",
    "    print(indexLst)\n",
    "\n",
    "    return indexLst\n",
    "\n",
    "'''This function is to read inside a sentence and extract tags'''\n",
    "def getConnlofChunk(index, lst):\n",
    "    try:\n",
    "        pat= \"[1-9]+\\s*\\(\\(\\s*([A-Z]+)\\s*<fs\\s*name=\\'([A-Z1-9]+)\\'\\s*drel=\\'([a-z0-9]+):([A-Z0-9]+)\\'>\\n\"\n",
    "        m=re.match(pat, lst[index-1])\n",
    "        if m:\n",
    "            print(m.group(0))\n",
    "            print(m.group(1))\n",
    "            chunkType=m.group(1)\n",
    "            print(m.group(2))\n",
    "            chunkIs=m.group(2)\n",
    "            print(m.group(3))\n",
    "            relType=m.group(3)\n",
    "            attachEd=m.group(4)\n",
    "            print(attachEd)\n",
    "            print(m.group(5))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        pat= \"[1-9]+\\s*\\(\\(\\s*([A-Z]+)\\s*<fs\\s+af=\\'([A-Za-z0-9,]+)\\'\\s+name=\\'([A-Z1-9]+)\\'\\s*drel=\\'([a-z0-9]+):([A-Z0-9]+)\\'>\\n\"\n",
    "        m=re.match(pat,lst[index-1])\n",
    "        if m:\n",
    "            print(m.group(1))\n",
    "            chunkType=m.group(1)\n",
    "            print(m.group(2))\n",
    "            chunkIs=m.group(2)\n",
    "            print(m.group(3))\n",
    "            relType=m.group(3)\n",
    "            attachEd=m.group(4)\n",
    "            print(attachEd)\n",
    "            print(m.group(5))\n",
    "    \n",
    "    except Exception:\n",
    "        pass\n",
    "        \n",
    "    '''This loop is for reading the tokens inside the chunk, please store them separately with some identifier'''\n",
    "    pat2=\"[0-9]+\\.[0-9]+\\s+([a-zA-Z]+)\\s+([A-Z_]+)\\s+<fs\\s+af=\\'([A-Za-z0-9,]+)\\'\\s+name=\\'([A-Za-z]+)\\'>\"\n",
    "    while True:\n",
    "        index=index+1\n",
    "        m=re.match(pat, lst[index-1])\n",
    "        if m:\n",
    "            print(m.group(1))\n",
    "            tocken=m.group(1)\n",
    "            print(m.group(2))\n",
    "            PoS=m.group(2)\n",
    "            print(m.group(3))\n",
    "            PoS=m.group(3)\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return\n",
    "\n",
    "        \n",
    "    return; #@rajesh, here you need to return the dictionary for each sentences\n",
    "\n",
    "\n",
    "def getConllofSentence(lst):\n",
    "    conllList=[];\n",
    "    chunkIndexLst=getChunkIndex(lst);\n",
    "\n",
    "    for element in chunkIndexLst:\n",
    "        getConnlofChunk(element,lst);\n",
    "        #conllList.extend(listofTockensConll);\n",
    "\n",
    "#     print(conllList)\n",
    "\n",
    "    return;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "'''Main'''\n",
    "fileId=open('bengali_sample.txt','r')\n",
    "lst=readSentence(fileId)\n",
    "\n",
    "print(len(lst))\n",
    "# getConllofSentence(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
